---
layout: about
title: about
permalink: /

profile:
  align: right
  image: prof_pic.jpg
  address: >

news: false  # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---


Hello! I am a third year Ph.D. student at MIT, where I am advised by [Jacob Andreas][jacob]. 

My research interests lie at the intersection of reinforcement learning (RL) and large language models (LLMs).
<!-- I believe that RL and LLMs can synergistically improve each other.  -->
I am very excited by the potential of RL to improve reasoning, math, coding, and other capabilities in LLMs. 
<!-- Similarly, I am also interested in harnessing the common-sense knowledge of LLMâ€™s to bootstrap RL. -->
Currently, I am thinking about how RL can be used to improve calibration and reduce hallucinations in LLMs.  
Finally, I have also been thinking about the paradigm of [inference-time compute][compute], and how optimally selecting inference-time techniques can significantly improve the efficiency of LLMs.   
<!-- Finally, having worked on multi-agent RL in the past, I am also interested in studying cooperation in multi-agent settings, with a particular focus on understanding how LLM agents can be integrated into and benefit from multi-agent frameworks.  -->

Previously, I worked with [Lerrel Pinto][lerrel] at NYU on developing automatic curriculum learning methods for RL agents. Before that, I was a part of the [MARMot Lab][marmot] at NUS, where I worked with [Guillaume Sartoretti][guillaume] on applying multi-agent reinforcement learning to [traffic signal control][traffic] and [multi-agent pathfinding][mapf]. 

I'm always excited to explore new research directions and am open to collaborating or advising students. If you are interested in my research or simply want to chat, don't hesitate to get in touch!

[compute]: https://arxiv.org/abs/2410.04707
[marmot]: https://marmotlab.org
[guillaume]: https://marmotlab.org/bio.html
[cilvr]: https://wp.nyu.edu/cilvr/ 
[lerrel]: https://www.lerrelpinto.com 
[ntu]: https://www.ntu.edu.sg/
[curriculum]: https://lilianweng.github.io/lil-log/2020/01/29/curriculum-for-reinforcement-learning.html
[traffic]: https://marmotlab.org/projects/urban_traffic.html
[mapf]: https://ieeexplore.ieee.org/abstract/document/9366340
[cathy]: http://www.wucathy.com/blog/ 
[dylan]: https://algorithmicalignment.csail.mit.edu  
[jacob]: https://www.mit.edu/~jda/
